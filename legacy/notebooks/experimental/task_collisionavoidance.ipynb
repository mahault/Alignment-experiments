{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d254db",
   "metadata": {},
   "source": [
    "# Collision Avoidance Task\n",
    "\n",
    "### Overview\n",
    "This notebook demonstrates single- and multi-agent planning in a cooperative collision avoidance task using sophisticated active inference and Theory of Mind (ToM) capabilities.\n",
    "\n",
    "### Task Description\n",
    "The collision avoidance task occurs in a 3Ã—3 grid environment. Agents begin at opposing corners of the grid and must traverse to the opposite corner without occupying the same location as the other agent (i.e., they must avoid colliding with one another).\n",
    "\n",
    "### Key Features Demonstrated\n",
    "Note that all agents conduct planning via sophisticated inference and we use the `another_works_for_tom` branch of pymdp. We do not include single agent scenarios here as this task requires more than one agent. We do not include the experiment with the pymdp rollout function as it does not accommodate for multiple agents to be in one shared environment.\n",
    "\n",
    "1. **Optimized Multiple non-ToM Agents** - uses our custom rollout function with planning tree recycling that supports multiple agents in one shared environment.\n",
    "\n",
    "2. **Single ToM Agent with Multiple non-ToM Agents** - one agent planning with theory of mind capabilities alongside two agents without theory of mind capabilities. Uses our custom rollout function which accommodates both planning strategies, planning tree recycling, and multiple agents in one shared environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import jax.tree_util as jtu\n",
    "import equinox as eqx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tom.envs import CollisionAvoidanceEnv\n",
    "from tom.models import CollisionAvoidanceModel, CollisionAvoidanceAgent\n",
    "from tom.planning.visualize import visualize_plan_tree, visualize_beliefs, visualize_env\n",
    "\n",
    "from tom.planning.si import si_policy_search as si_policy_search_nontom\n",
    "from tom.planning.si_tom import si_policy_search_tom, ToMify\n",
    "\n",
    "from pymdp.envs import rollout as rollout_pymdp\n",
    "from tom.planning.rollout_deprecated import rollout as rollout_optimized\n",
    "from tom.planning.rollout_tom_deprecated import rollout as rollout_tom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41fa849",
   "metadata": {},
   "source": [
    "# Optimized Mulitple non-ToM Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60171247",
   "metadata": {},
   "source": [
    "Initialize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c5ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 3\n",
    "num_agents = 2\n",
    "initial_positions = jnp.array([0, 8]) # can set to None and it will be initialised randomly\n",
    "\n",
    "env = CollisionAvoidanceEnv(num_agents, grid_size, initial_positions) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74719756",
   "metadata": {},
   "source": [
    "Initialize the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1.0\n",
    "\n",
    "model_agent0 = CollisionAvoidanceModel(agent_idx=0)\n",
    "model_agent1 = CollisionAvoidanceModel(agent_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b08155",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent0 = CollisionAvoidanceAgent(model_agent0, gamma=gamma, batch_size=1)\n",
    "agent1 = CollisionAvoidanceAgent(model_agent1, gamma=gamma, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b31ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = jtu.tree_map(lambda x,y: jnp.concatenate([x,y], axis=0), agent0, agent1)\n",
    "\n",
    "# policies should remain of shape (9, 1, 2) - the same for all agents in the batch; the line above results in (18, 1, 2)\n",
    "agents = eqx.tree_at(lambda x: x.policies, agents, agent0.policies)\n",
    "\n",
    "# but now, we need to update the batch_size and since it's a static field, we need to use object.__setattr__ to bypass eqx's immutability\n",
    "object.__setattr__(agents, 'batch_size', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0119b89",
   "metadata": {},
   "source": [
    "We first set up the non-tom planning algorithm. We then run the agent using the our custom rollout function function which, in addition to recycling the planning tree for better performance, allows multiple agents to be in a shared environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon=3\n",
    "max_nodes = 5000\n",
    "max_branching = 10\n",
    "policy_prune_threshold = 1 / 8\n",
    "observation_prune_threshold = 1 / 8\n",
    "entropy_stop_threshold = 0.5\n",
    "efe_stop_threshold = 5\n",
    "kl_threshold=1e-2\n",
    "prune_penalty = 512\n",
    "\n",
    "# set up the policy search function\n",
    "tree_search_nontom = si_policy_search_nontom(\n",
    "        horizon=horizon,\n",
    "        max_nodes=max_nodes,\n",
    "        max_branching=max_branching,\n",
    "        policy_prune_threshold=policy_prune_threshold,\n",
    "        observation_prune_threshold=observation_prune_threshold,\n",
    "        entropy_stop_threshold=entropy_stop_threshold,\n",
    "        efe_stop_threshold=efe_stop_threshold,\n",
    "        kl_threshold=kl_threshold,\n",
    "        prune_penalty=prune_penalty,\n",
    "        gamma=gamma\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae732849",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 3\n",
    "key = jr.PRNGKey(1)\n",
    "last, info_optimized_multi_nontom, env = rollout_optimized(agents, env, T, key, policy_search=tree_search_nontom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_env(info_optimized_multi_nontom, model=model_agent0, save_as_gif=False, gif_filename=\"collisionavoidance_optimized_multi_nontom.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_plan_tree(info_optimized_multi_nontom, time_idx=0, agent_idx=0, model=model_agent0, min_prob = 0.0, depth=4, fig_size = (5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a6e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_beliefs(info_optimized_multi_nontom, model=model_agent0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39732c5d",
   "metadata": {},
   "source": [
    "# Single ToM Agent with Multiple non-ToM Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a1d2f",
   "metadata": {},
   "source": [
    "Initialize the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f55de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "\n",
    "agent0 = CollisionAvoidanceAgent(model_agent0, gamma=gamma, batch_size=1)\n",
    "focal_agent = ToMify(agent0,\n",
    "                     self_states=[0],\n",
    "                     world_states=[],\n",
    "                     # observation mappings is of size (focal_batch, num_agents, num_modalities)\n",
    "                     # with for each obs modality of the agent, which actual received obs modality should be used\n",
    "                     # e.g. you'll get 2 observation modalities,\n",
    "                     # these map to obs modality [0, 1] for agent 0 (focal) and [1, nothing] for agent 1 (other)\n",
    "                     observation_mappings=jnp.array([[[0, 1],[1, -1]]]), # note that observations from the environment include the locations of the other agents so we have observation mappings that tell us which observation is regarding which agent (-1s are invalid)\n",
    "                     # state mappings is of size (focal_batch, num_other_agents, num_state_factors)\n",
    "                     # and its meaning is, for each other agent, we specify whether a focal agent's state factor maps to one of this other agent's state factors\n",
    "                     # -1 meaning that none of the other agent's state factors map to this one\n",
    "                     # so here it means that for the other agent, the 0th focal state factor has no mapping (-1), but the 1st focal state factor maps to the 0th of the other\n",
    "                     state_mappings=[[[-1, 0]]])\n",
    "\n",
    "# we have to set the preferences for the focal agent's beliefs about the other agents correctly here otherwise it just copies its own model (and its own preferences)\n",
    "focal_agent = eqx.tree_at(lambda x: x.agent_models.C, focal_agent, [c[None, ...] for c in agents.C])\n",
    "\n",
    "other_agents = CollisionAvoidanceAgent(model_agent1, gamma=gamma, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ec8dc0",
   "metadata": {},
   "source": [
    "Running the agent using the sophisticated inference planning with theory of mind capabilities (`si_policy_search_tom`) and the custom rollout function which allows non-ToM and ToM agents to interact within the same environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nodes = 10000\n",
    "\n",
    "tree_search_tom = si_policy_search_tom(\n",
    "            horizon=horizon,\n",
    "            max_nodes=max_nodes,\n",
    "            max_branching=max_branching,\n",
    "            policy_prune_threshold=policy_prune_threshold,\n",
    "            observation_prune_threshold=observation_prune_threshold,\n",
    "            entropy_stop_threshold=entropy_stop_threshold,\n",
    "            efe_stop_threshold=efe_stop_threshold,\n",
    "            kl_threshold=kl_threshold,\n",
    "            prune_penalty=prune_penalty,\n",
    "            gamma=gamma,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83619b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.PRNGKey(1)\n",
    "T=3\n",
    "last, info_tom, env = rollout_tom(focal_agent,\n",
    "            other_agents,\n",
    "            env,\n",
    "            T,\n",
    "            key,\n",
    "            other_agent_policy_search=tree_search_nontom,\n",
    "            focal_agent_tom_policy_search=tree_search_tom,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981839e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_env(info_tom, model=model_agent0, save_as_gif=False, gif_filename=\"collisionavoidance_tom.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8120e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_plan_tree(info_tom, time_idx=0, agent_idx=0, model=model_agent0, min_prob = 0.0, depth=4, fig_size = (5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to print out the beliefs of focal agent at tree nodes\n",
    "\n",
    "tree = jtu.tree_map(lambda x: x[0,0], info_tom[\"tree\"])\n",
    "\n",
    "def print_qs(tree, node_idx):\n",
    "    print(\"focal agent:\")\n",
    "    print(\"  location focal \\n\", jnp.round(tree[node_idx][\"qs\"][0][0, 0, 0], 2))\n",
    "    print(\"  location other: \\n\", jnp.round(tree[node_idx][\"qs\"][1][0, 0, 0], 2))\n",
    "    print(\"other agent:\")\n",
    "    print(\"  location other (self): \\n\", jnp.round(tree[node_idx][\"qs\"][0][0, 1, 0], 2))\n",
    "    print(\"  location focal: \\n\", jnp.round(tree[node_idx][\"qs\"][1][0, 1, 0], 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
