{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d254db",
   "metadata": {},
   "source": [
    "# Foraging Task\n",
    "\n",
    "### Overview\n",
    "This notebook demonstrates multi-agent planning with and without Theory of Mind (ToM) in a cooperative foraging task using sophisticated active inference. These experiments are published in: [\"Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation\"](https://arxiv.org/abs/2508.00401). Note that in the paper, locations are numbered 1–9, but in the codebase, they start at 0 instead of 1 (i.e., 0–8).\n",
    "\n",
    "### Task Description\n",
    "The foraging task takes place in a 3×3 grid environment where agents must collect apples that spawn at a rate of 0.25. Agents must coordinate their actions to efficiently gather resources whilst avoiding redundant efforts.\n",
    "\n",
    "### Experiments\n",
    "All agents use sophisticated inference planning with the `another_works_for_tom` branch of pymdp.\n",
    "\n",
    "1. **Two non-ToM Agents** - Two agents planning without Theory of Mind capabilities. Uses our custom rollout function with planning tree recycling that supports multiple agents in a shared environment.\n",
    "\n",
    "2. **One ToM Agent with One non-ToM Agent** - One agent with Theory of Mind capabilities cooperating with one agent without Theory of Mind capabilities. Uses our custom rollout function which accommodates both non-ToM and ToM planning strategies and multiple agents in one shared environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import jax.tree_util as jtu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tom.envs import ForagingEnv\n",
    "from tom.models import ForagingModel, ForagingAgent\n",
    "from tom.planning.visualize import visualize_plan_tree, visualize_env\n",
    "\n",
    "from tom.planning.si import si_policy_search as si_policy_search_nontom\n",
    "from tom.planning.si_tom import si_policy_search_tom, ToMify\n",
    "\n",
    "from tom.planning.rollout import rollout as rollout_nontom\n",
    "from tom.planning.rollout_tom import rollout as rollout_tom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41fa849",
   "metadata": {},
   "source": [
    "# Two non-ToM Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60171247",
   "metadata": {},
   "source": [
    "Initialize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c5ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 3\n",
    "apple_spawn_rate = 0.25\n",
    "num_agents = 2\n",
    "initial_positions = jnp.array([7, 5])\n",
    "\n",
    "env = ForagingEnv(apple_spawn_rate, num_agents, grid_size, initial_positions) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74719756",
   "metadata": {},
   "source": [
    "Initialize the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1.0\n",
    "\n",
    "model = ForagingModel(apple_spawn_rate=apple_spawn_rate)\n",
    "agents = ForagingAgent(model, gamma=gamma, batch_size=num_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0119b89",
   "metadata": {},
   "source": [
    "Set up the non-ToM planning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f676c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon=3\n",
    "max_nodes = 5000\n",
    "max_branching = 6\n",
    "policy_prune_threshold = 1 / 8\n",
    "observation_prune_threshold = 1 / 8\n",
    "entropy_stop_threshold = 0.5\n",
    "efe_stop_threshold = 10\n",
    "kl_threshold=1e-2\n",
    "prune_penalty = 512\n",
    "\n",
    "# set up the policy search function\n",
    "tree_search_nontom = si_policy_search_nontom(\n",
    "        horizon=horizon,\n",
    "        max_nodes=max_nodes,\n",
    "        max_branching=max_branching,\n",
    "        policy_prune_threshold=policy_prune_threshold,\n",
    "        observation_prune_threshold=observation_prune_threshold,\n",
    "        entropy_stop_threshold=entropy_stop_threshold,\n",
    "        efe_stop_threshold=efe_stop_threshold,\n",
    "        kl_threshold=kl_threshold,\n",
    "        prune_penalty=prune_penalty,\n",
    "        gamma=gamma\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5b48cd",
   "metadata": {},
   "source": [
    "Running the agent using the sophisticated inference planning without theory of mind capabilities (`si_policy_search_nontom`) and the custom rollout function which allows multiple agents to interact within the same environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae732849",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2\n",
    "key = jr.PRNGKey(1)\n",
    "last, info_nontom, env = rollout_nontom(agents, env, T, key, policy_search=tree_search_nontom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_env(info_nontom, model=model, save_as_gif=False, gif_filename=\"foraging_nontom.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1624f9",
   "metadata": {},
   "source": [
    "Plan tree of the red non-ToM agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f1e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_plan_tree(info_nontom, time_idx=0, agent_idx=0, model=model, depth=4, fig_size=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996fa183",
   "metadata": {},
   "source": [
    "Plan tree of the purple non-ToM agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e79164",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_plan_tree(info_nontom, time_idx=0, agent_idx=1, model=model, depth=4, fig_size=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39732c5d",
   "metadata": {},
   "source": [
    "# One ToM Agent with One non-ToM Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678b0d42",
   "metadata": {},
   "source": [
    "Initialize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 3\n",
    "apple_spawn_rate = 0.25\n",
    "num_agents = 2\n",
    "initial_positions = jnp.array([7, 5]) \n",
    "\n",
    "env = ForagingEnv(apple_spawn_rate, num_agents, grid_size, initial_positions) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a1d2f",
   "metadata": {},
   "source": [
    "Initialize the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f55de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ForagingModel(apple_spawn_rate)\n",
    "\n",
    "agent0 = ForagingAgent(model, gamma=gamma, batch_size=1)\n",
    "focal_agent = ToMify(agent0,\n",
    "                     self_states=[0, 1],\n",
    "                     world_states=[2, 3, 4, 5, 6, 7],\n",
    "                     # observation mappings is of size (focal_batch, num_agents, num_modalities)\n",
    "                     # for each obs modality of the agent, we set which actual received obs modality should be used\n",
    "                     # e.g. you'll get 3 observation modalities,\n",
    "                     # these map to obs modality [0, 1, 2] for agent 0 (focal) and \n",
    "                     # [3, nothing, nothing] for agent 1 (other) - i.e., the 3rd observation maps onto the other agent's own location (0th modality)\n",
    "                     observation_mappings=jnp.array([[[0,1,2],[0,-1,-1]]]))\n",
    "\n",
    "other_agents = ForagingAgent(model, gamma=gamma, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ec8dc0",
   "metadata": {},
   "source": [
    "Running the agent using the sophisticated inference planning with theory of mind capabilities (`si_policy_search_tom`) and the custom rollout function which allows non-ToM and ToM agents to interact within the same environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_search_tom = si_policy_search_tom(\n",
    "            horizon=horizon,\n",
    "            max_nodes=max_nodes,\n",
    "            max_branching=max_branching,\n",
    "            policy_prune_threshold=policy_prune_threshold,\n",
    "            observation_prune_threshold=observation_prune_threshold,\n",
    "            entropy_stop_threshold=entropy_stop_threshold,\n",
    "            efe_stop_threshold=efe_stop_threshold,\n",
    "            kl_threshold=kl_threshold,\n",
    "            prune_penalty=prune_penalty,\n",
    "            gamma=gamma,\n",
    "            other_agent_policy_search=tree_search_nontom\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83619b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.PRNGKey(1)\n",
    "T=2\n",
    "last, info_tom, env = rollout_tom(focal_agent,\n",
    "            other_agents,\n",
    "            env,\n",
    "            T,\n",
    "            key,\n",
    "            other_agent_policy_search=tree_search_nontom,\n",
    "            focal_agent_tom_policy_search=tree_search_tom,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981839e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_env(info_tom, model=model, save_as_gif=False, gif_filename=\"foraging_tom.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224df961",
   "metadata": {},
   "source": [
    "Plan tree of the red focal (ToM) agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da974c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_plan_tree(info_tom, time_idx=2, agent_idx=0, model=model, depth=8, root_idx=0, fig_size=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97b9a97",
   "metadata": {},
   "source": [
    "Plan tree of the purple non-ToM agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98bdcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_plan_tree(info_tom, time_idx=0, agent_idx=1, plotting_other_intom=True, model=model, depth=8, fig_size=(10,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
