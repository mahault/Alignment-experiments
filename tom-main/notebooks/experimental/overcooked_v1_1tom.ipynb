{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import jax.random as jr\n",
        "import jax.tree_util as jtu\n",
        "import jax.numpy as jnp\n",
        "\n",
        "from tom.models import OvercookedModel, OvercookedAgent\n",
        "from jaxmarl.viz.overcooked_visualizer import OvercookedVisualizer\n",
        "\n",
        "from jaxmarl.environments.overcooked import overcooked_layouts, layout_grid_to_dict\n",
        "from tom.envs.env_ocv1 import OvercookedV1Env\n",
        "\n",
        "from tom.planning.rollout_tom import rollout as rollout_tom\n",
        "from tom.planning.si_tom import si_policy_search_tom, ToMify\n",
        "from tom.planning.si import si_policy_search as si_policy_search_nontom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjRnlRuH1654"
      },
      "source": [
        "# Overcooked_v1 with 1 ToM agent and 1 non-ToM agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialise the environment\n",
        "\n",
        "- W = wall\n",
        "- O = onion pile\n",
        "- P = pot\n",
        "- A = agent\n",
        "- B = plate pile\n",
        "- X = delivery station\n",
        "- empty spaces are empty cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "custom_layout_grid = \"\"\"\n",
        "WWPWW\n",
        "OA  W\n",
        "W  AB\n",
        "WWXWW\n",
        "\"\"\"\n",
        "layout = layout_grid_to_dict(custom_layout_grid)\n",
        "\n",
        "# # or if you want to use a pre-set layout\n",
        "# layout = overcooked_layouts[\"cramped_room\"] # options: cramped_room, asymm_advantages, coord_ring, forced_coord, counter_circuit\n",
        "\n",
        "num_agents = 2\n",
        "timesteps = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = OvercookedV1Env(num_agents, layout, timesteps, initiate_inventory=None)\n",
        "# env = OvercookedV1Env(num_agents, layout, timesteps, initiate_inventory=[\"onion\", \"empty\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialise pymdp agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = OvercookedModel(env_layout=layout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent0 = OvercookedAgent(model, batch_size = 1)\n",
        "obs_mapping = jnp.array([[list(range(len(model.A.keys()))), list(range(len(model.A.keys())))]])\n",
        "\n",
        "focal_agent = ToMify(\n",
        "    agent0,\n",
        "    self_states=[0, 1, 2],\n",
        "    world_states=list(range(3,len(model.B.keys()))),\n",
        "    observation_mappings=obs_mapping,\n",
        "    batch_size=1\n",
        ")\n",
        "\n",
        "other_agent = OvercookedAgent(model, batch_size = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "focal_agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Do the rollout using sophisticated active inference (2 ToM agents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "horizon=3\n",
        "max_nodes = 20000\n",
        "max_branching = len(model.B[0].batch[\"actions\"])\n",
        "policy_prune_threshold = 0.0\n",
        "observation_prune_threshold = 1/64\n",
        "entropy_stop_threshold = 0.5\n",
        "efe_stop_threshold = 1000\n",
        "kl_threshold=-1\n",
        "prune_penalty = 512\n",
        "gamma = 8.0\n",
        "topk_obsspace = 1\n",
        "\n",
        "# set up the policy search function\n",
        "tree_search_nontom = si_policy_search_nontom(\n",
        "        horizon=horizon,\n",
        "        max_nodes=max_nodes,\n",
        "        max_branching=max_branching,\n",
        "        policy_prune_threshold=policy_prune_threshold,\n",
        "        observation_prune_threshold=observation_prune_threshold,\n",
        "        entropy_stop_threshold=entropy_stop_threshold,\n",
        "        efe_stop_threshold=efe_stop_threshold,\n",
        "        kl_threshold=kl_threshold,\n",
        "        prune_penalty=prune_penalty,\n",
        "        gamma=gamma,\n",
        "        topk_obsspace=topk_obsspace\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "horizon=5\n",
        "max_nodes = 20000\n",
        "max_branching = len(model.B[0].batch[\"actions\"])\n",
        "policy_prune_threshold = 0.0\n",
        "observation_prune_threshold = 1/64\n",
        "entropy_stop_threshold = 0.5\n",
        "efe_stop_threshold = 1000\n",
        "kl_threshold=-1\n",
        "prune_penalty = 512\n",
        "gamma = 8.0\n",
        "topk_obsspace = 1\n",
        "\n",
        "# set up the policy search function\n",
        "tree_search_tom = si_policy_search_tom(\n",
        "            horizon=horizon,\n",
        "            max_nodes=max_nodes,\n",
        "            max_branching=max_branching,\n",
        "            policy_prune_threshold=policy_prune_threshold,\n",
        "            observation_prune_threshold=observation_prune_threshold,\n",
        "            entropy_stop_threshold=entropy_stop_threshold,\n",
        "            efe_stop_threshold=efe_stop_threshold,\n",
        "            kl_threshold=kl_threshold,\n",
        "            prune_penalty=prune_penalty,\n",
        "            gamma=gamma,\n",
        "            other_agent_policy_search=tree_search_nontom\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "key = jr.PRNGKey(1)\n",
        "last, info_tom, env = rollout_tom(\n",
        "    focal_agent,\n",
        "    other_agent,\n",
        "    env,\n",
        "    timesteps,\n",
        "    key,\n",
        "    other_agent_policy_search=tree_search_nontom,\n",
        "    focal_agent_tom_policy_search=tree_search_tom,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding visualisations and printing information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_State_sequence(info_State):\n",
        "    num_timesteps = info_State.time.shape[0]\n",
        "    \n",
        "    state_seq = []\n",
        "    for t in range(num_timesteps):\n",
        "        state_t = jtu.tree_map(\n",
        "            lambda x: x[t] if x.ndim == 1 else x[:, t, ...],\n",
        "            info_State\n",
        "        )\n",
        "        state_seq.append(state_t)\n",
        "    \n",
        "    return state_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state_seq = convert_State_sequence(info_tom[\"env_state\"])\n",
        "viz = OvercookedVisualizer()\n",
        "viz.animate(state_seq, agent_view_size=5, filename='overcooked_v1_1tom_test.gif', fps=3.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import jax.numpy as jnp\n",
        "\n",
        "def print_beliefs(model, qs, belief_idx):\n",
        "    state_factor_names = list(model.B.keys())\n",
        "    state_factor_name = state_factor_names[belief_idx]\n",
        "    \n",
        "    labels = model.B[state_factor_name].batch[state_factor_name]\n",
        "    \n",
        "    for agent_idx, agent_beliefs in enumerate(qs[belief_idx]):\n",
        "        print(f\"AGENT {agent_idx} {state_factor_name} BELIEFS:\")\n",
        "        \n",
        "        for t in range(agent_beliefs.shape[0]):\n",
        "            most_likely_idx = jnp.argmax(agent_beliefs[t])\n",
        "            probability = agent_beliefs[t, 0, most_likely_idx]\n",
        "            print(f\"  time {t}: {labels[most_likely_idx]} (prob={probability:.3f})\")\n",
        "        print()\n",
        "\n",
        "def print_actions(actions):\n",
        "    action_names = model.B[list(model.B.keys())[0]].batch['actions']\n",
        "    \n",
        "    for agent_idx, agent_actions in enumerate(actions):\n",
        "        print(f\"AGENT {agent_idx} ACTIONS:\")\n",
        "        \n",
        "        for t in range(agent_actions.shape[0]):\n",
        "            action_idx = agent_actions[t][0] if agent_actions[t].ndim > 0 else agent_actions[t]\n",
        "            print(f\"  time {t}: {action_names[action_idx]}\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_beliefs(model,info_tom[\"qs\"], belief_idx=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_actions(info_tom[\"action\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from tom.planning.visualize import visualize_plan_tree\n",
        "# root_idx = None\n",
        "# visualize_plan_tree(info_nontom, time_idx=0, agent_idx=1, model=model, min_prob=0.0, depth=4, fig_size = (8,10), root_idx=root_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
