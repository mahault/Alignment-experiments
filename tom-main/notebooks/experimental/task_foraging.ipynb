{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d254db",
   "metadata": {},
   "source": [
    "# Foraging Task\n",
    "\n",
    "### Overview\n",
    "This notebook demonstrates single- and multi-agent planning in a cooperative foraging task using sophisticated active inference and Theory of Mind (ToM) capabilities.\n",
    "\n",
    "### Task Description\n",
    "The foraging task occurs in a 3Ã—3 grid environment where agents must eat apples that spawn in the orchard at a set rate.\n",
    "\n",
    "### Key Features Demonstrated\n",
    "Note that all agents conduct planning via sophisticated inference and we use the `another_works_for_tom` branch of pymdp.\n",
    "\n",
    "1. **Single non-ToM Agent** - uses the `pymdp` rollout function.\n",
    "\n",
    "2. **Optimized Single non-ToM Agent** - uses our custom rollout function with planning tree recycling for improved performance.\n",
    "\n",
    "3. **Multiple non-ToM Agents** - uses our custom rollout function with planning tree recycling that also supports multiple agents in one shared environment.\n",
    "\n",
    "4. **Single ToM Agent with Multiple non-ToM Agents** - one agent planning with theory of mind capabilities alongside two agents without theory of mind capabilities. Uses our custom rollout function which accommodates both planning strategies and multiple agents in one shared environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import jax.tree_util as jtu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tom.envs import ForagingEnv\n",
    "from tom.models import ForagingModel, ForagingAgent\n",
    "from tom.planning.visualize import visualize_plan_tree, visualize_beliefs, visualize_env, plot_plan_tree\n",
    "\n",
    "from tom.planning.si import si_policy_search as si_policy_search_nontom\n",
    "from tom.planning.si_tom import si_policy_search_tom, ToMify\n",
    "\n",
    "from pymdp.envs import rollout as rollout_pymdp\n",
    "from tom.planning.rollout_deprecated import rollout as rollout_optimized\n",
    "from tom.planning.rollout_tom_deprecated import rollout as rollout_tom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf4909",
   "metadata": {},
   "source": [
    "# Single Non-ToM Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becbb45b",
   "metadata": {},
   "source": [
    "Initialize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 3\n",
    "num_agents = 1\n",
    "apple_spawn_rate = 0.1\n",
    "initial_positions = jnp.array([4]) # can set to None and it will be initialised randomly\n",
    "\n",
    "env = ForagingEnv(apple_spawn_rate, num_agents, grid_size, initial_positions) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a27f2e8",
   "metadata": {},
   "source": [
    "Initialize the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a74660",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1.0\n",
    "\n",
    "model = ForagingModel(apple_spawn_rate=apple_spawn_rate)\n",
    "agents = ForagingAgent(model, gamma=gamma, batch_size=num_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1469971",
   "metadata": {},
   "source": [
    "Running the agent using the sophisticated inference non-tom planning (`si_policy_search_nontom`) and the `pymdp` rollout function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon=3\n",
    "max_nodes = 5000\n",
    "max_branching = 6\n",
    "policy_prune_threshold = 1 / 32\n",
    "observation_prune_threshold = 1 / 32\n",
    "entropy_stop_threshold = 0.5\n",
    "efe_stop_threshold = 5\n",
    "kl_threshold=1e-2\n",
    "prune_penalty = 512\n",
    "\n",
    "# set up the policy search function\n",
    "tree_search_nontom = si_policy_search_nontom(\n",
    "        horizon=horizon,\n",
    "        max_nodes=max_nodes,\n",
    "        max_branching=max_branching,\n",
    "        policy_prune_threshold=policy_prune_threshold,\n",
    "        observation_prune_threshold=observation_prune_threshold,\n",
    "        entropy_stop_threshold=entropy_stop_threshold,\n",
    "        efe_stop_threshold=efe_stop_threshold,\n",
    "        kl_threshold=kl_threshold,\n",
    "        prune_penalty=prune_penalty,\n",
    "        gamma=gamma\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a8c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "key = jr.PRNGKey(1)\n",
    "last, info_single_nontom, env = rollout_pymdp(agents, env, T, key, policy_search=tree_search_nontom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_env(info_single_nontom, model=model, save_as_gif=False, gif_filename=\"foraging_single_nontom.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2470135",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_plan_tree(info_single_nontom, time_idx=4, agent_idx=0, model=model, min_prob=0.0, depth=4, fig_size = (5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff70fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_beliefs(info_single_nontom, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8abf02b",
   "metadata": {},
   "source": [
    "# Optimized Single Non-ToM Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea9732",
   "metadata": {},
   "source": [
    "The environment, agent, and planning algorithm set up are the same as above. We now just run the agent using the our custom rollout function function which recycles the planning tree for better performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf0bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "key = jr.PRNGKey(1)\n",
    "last, info_optimized_single_nontom, env = rollout_optimized(agents, env, T, key, policy_search=tree_search_nontom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218bcdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_env(info_optimized_single_nontom, model=model, save_as_gif=False, gif_filename=\"foraging_optimized_single_nontom.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_plan_tree(info_optimized_single_nontom, time_idx=0, agent_idx=0, model=model, fig_size = (5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41fa849",
   "metadata": {},
   "source": [
    "# Mulitple non-ToM Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60171247",
   "metadata": {},
   "source": [
    "Initialize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c5ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 3\n",
    "apple_spawn_rate = 0.1\n",
    "num_agents = 3\n",
    "initial_positions = jnp.array([7, 5, 1]) # can set to None and it will be initialised randomly\n",
    "\n",
    "env = ForagingEnv(apple_spawn_rate, num_agents, grid_size, initial_positions) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74719756",
   "metadata": {},
   "source": [
    "Initialize the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1.0\n",
    "\n",
    "model = ForagingModel(apple_spawn_rate=apple_spawn_rate)\n",
    "agents = ForagingAgent(model, gamma=gamma, batch_size=num_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0119b89",
   "metadata": {},
   "source": [
    "The non-tom planning algorithm set up is the same as above. We now just run the agent using the our custom rollout function function which, in addition to recycling the planning tree for better performance, allows multiple agents to be in a shared environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae732849",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "key = jr.PRNGKey(1)\n",
    "last, info_optimized_multi_nontom, env = rollout_optimized(agents, env, T, key, policy_search=tree_search_nontom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_env(info_optimized_multi_nontom, model=model, save_as_gif=False, gif_filename=\"foraging_optimized_multi_nontom.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f1e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_plan_tree(info_optimized_multi_nontom, time_idx=0, agent_idx=0, model=model, depth=4, fig_size = (5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39732c5d",
   "metadata": {},
   "source": [
    "# Single ToM Agent with Multiple non-ToM Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678b0d42",
   "metadata": {},
   "source": [
    "Initialize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 3\n",
    "apple_spawn_rate = 0.1\n",
    "num_agents = 3\n",
    "initial_positions = jnp.array([7, 5, 1]) # can set to None and it will be initialised randomly\n",
    "\n",
    "env = ForagingEnv(apple_spawn_rate, num_agents, grid_size, initial_positions) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a1d2f",
   "metadata": {},
   "source": [
    "Initialize the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f55de",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent0 = ForagingAgent(model, gamma=gamma, batch_size=1)\n",
    "focal_agent = ToMify(agent0,\n",
    "                     self_states=[0, 1],\n",
    "                     world_states=[2, 3, 4, 5, 6, 7],\n",
    "                     observation_mappings=jnp.array([[[0,1,2],[3,-1,-1],[4,-1,-1]]]))\n",
    "\n",
    "# note that observations from the environment include the locations of the other agents so we have observation mappings that tell us which observation is regarding which agent (-1s are invalid)\n",
    "\n",
    "other_agents = ForagingAgent(model, gamma=1.0, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ec8dc0",
   "metadata": {},
   "source": [
    "Running the agent using the sophisticated inference planning with theory of mind capabilities (`si_policy_search_tom`) and the custom rollout function which allows non-ToM and ToM agents to interact within the same environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_search_tom = si_policy_search_tom(\n",
    "            horizon=horizon,\n",
    "            max_nodes=10_000,\n",
    "            max_branching=max_branching,\n",
    "            policy_prune_threshold=policy_prune_threshold,\n",
    "            observation_prune_threshold=observation_prune_threshold,\n",
    "            entropy_stop_threshold=entropy_stop_threshold,\n",
    "            efe_stop_threshold=efe_stop_threshold,\n",
    "            kl_threshold=kl_threshold,\n",
    "            prune_penalty=prune_penalty,\n",
    "            gamma=gamma,\n",
    "            other_agent_policy_search=tree_search_nontom\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83619b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.PRNGKey(1)\n",
    "T=10\n",
    "last, info_tom, env = rollout_tom(focal_agent,\n",
    "            other_agents,\n",
    "            env,\n",
    "            T,\n",
    "            key,\n",
    "            other_agent_policy_search=tree_search_nontom,\n",
    "            focal_agent_tom_policy_search=tree_search_tom,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981839e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_env(info_tom, model=model, save_as_gif=False, gif_filename=\"foraging_tom.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224df961",
   "metadata": {},
   "source": [
    "Plan tree of the focal (ToM) agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da974c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_plan_tree(info_tom, time_idx=0, agent_idx=0, model=model, depth=6, min_prob=0.0, root_idx=0, fig_size = (5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df24da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to print out the beliefs of focal agent at tree nodes\n",
    "\n",
    "tree = jtu.tree_map(lambda x: x[0,0], info_tom[\"tree\"])\n",
    "\n",
    "def print_qs(tree, node_idx):\n",
    "    states = jtu.tree_map(lambda x : [i[0].item() for i in jnp.argmax(x, axis=-1)[0]], tree[node_idx][\"qs\"])\n",
    "    print(\"location\", states[0])\n",
    "    print(\"rewards:\", states[1])\n",
    "    print(\"apples:\")\n",
    "    print( \" focal:  \", jnp.round(tree[node_idx][\"qs\"][2][0, 0, 0], 2), jnp.round(tree[node_idx][\"qs\"][3][0, 0, 0], 2), jnp.round(tree[node_idx][\"qs\"][4][0, 0, 0], 2))\n",
    "    print( \" other 1:\", jnp.round(tree[node_idx][\"qs\"][2][0, 1, 0], 2), jnp.round(tree[node_idx][\"qs\"][3][0, 1, 0], 2), jnp.round(tree[node_idx][\"qs\"][4][0, 1, 0], 2))\n",
    "    print( \" other 2:\", jnp.round(tree[node_idx][\"qs\"][2][0, 2, 0], 2), jnp.round(tree[node_idx][\"qs\"][3][0, 2, 0], 2), jnp.round(tree[node_idx][\"qs\"][4][0, 2, 0], 2))\n",
    "    print()\n",
    "    print( \" focal:  \", jnp.round(tree[node_idx][\"qs\"][5][0, 0, 0], 2), jnp.round(tree[node_idx][\"qs\"][6][0, 0, 0], 2), jnp.round(tree[node_idx][\"qs\"][7][0, 0, 0], 2))\n",
    "    print( \" other 1:\", jnp.round(tree[node_idx][\"qs\"][5][0, 1, 0], 2), jnp.round(tree[node_idx][\"qs\"][6][0, 1, 0], 2), jnp.round(tree[node_idx][\"qs\"][7][0, 1, 0], 2))\n",
    "    print( \" other 2:\", jnp.round(tree[node_idx][\"qs\"][5][0, 2, 0], 2), jnp.round(tree[node_idx][\"qs\"][6][0, 2, 0], 2), jnp.round(tree[node_idx][\"qs\"][7][0, 2, 0], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e700444",
   "metadata": {},
   "source": [
    "Plan tree of the other (non-ToM) agent 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_tree1 = jtu.tree_map(lambda x: x[0, 0], info_tom[\"other_tree\"])\n",
    "_ = plot_plan_tree(other_tree1, model=model, max_depth=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2becae",
   "metadata": {},
   "source": [
    "Plan tree that the focal agent imagined for other agent 1 (note that focal_other_tree has dims (num_tom_agents, num_timesteps, num_other_agents, ...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e06a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_other_tree1 = jtu.tree_map(lambda x: x[0, 0, 0], info_tom[\"focal_other_tree\"])\n",
    "_ = plot_plan_tree(focal_other_tree1, model=model, max_depth=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
